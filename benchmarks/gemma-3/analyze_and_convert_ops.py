#!/usr/bin/env python3
"""
Comprehensive analysis and conversion of Gemma ONNX model operations for EZKL compatibility
"""

import os
import json
import onnx
import numpy as np
import torch
import torch.nn as nn
from typing import List, Set, Dict, Any
import subprocess
import tempfile

class GemmaONNXAnalyzer:
    def __init__(self, model_path: str = "model.onnx"):
        self.model_path = model_path
        self.model = None
        self.operations = set()
        self.operation_counts = {}
        
    def load_model(self):
        """Load the ONNX model"""
        print("üîÑ Loading ONNX model...")
        try:
            self.model = onnx.load(self.model_path)
            print(f"‚úÖ Model loaded: {self.model_path}")
            print(f"   - Model IR version: {self.model.ir_version}")
            print(f"   - Opset version: {self.model.opset_import[0].version}")
            print(f"   - Producer: {self.model.producer_name}")
        except Exception as e:
            print(f"‚ùå Error loading model: {e}")
            return False
        return True
    
    def analyze_operations(self):
        """Analyze all operations in the ONNX model"""
        print("\nüîç Analyzing ONNX model operations...")
        
        if not self.model:
            print("‚ùå No model loaded")
            return
        
        # Collect all operations
        for node in self.model.graph.node:
            op_type = node.op_type
            self.operations.add(op_type)
            self.operation_counts[op_type] = self.operation_counts.get(op_type, 0) + 1
        
        print(f"‚úÖ Found {len(self.operations)} unique operation types:")
        print(f"   Total nodes: {len(self.model.graph.node)}")
        
        # Print operations with counts
        for op, count in sorted(self.operation_counts.items()):
            print(f"   - {op}: {count} occurrences")
    
    def get_ezkl_supported_operations(self) -> Set[str]:
        """Get list of operations supported by EZKL (version 13)"""
        print("\nüìã EZKL Supported Operations (v13):")
        
        # EZKL v13 supported operations based on documentation
        supported_ops = {
            # Basic operations
            'Add', 'Sub', 'Mul', 'Div', 'Pow', 'Sqrt', 'Exp', 'Log',
            'Abs', 'Neg', 'Floor', 'Ceil', 'Round',
            
            # Activation functions
            'Relu', 'Sigmoid', 'Tanh', 'Softmax', 'Gelu',
            
            # Matrix operations
            'MatMul', 'Gemm', 'Transpose', 'Reshape', 'Flatten',
            'Concat', 'Split', 'Slice', 'Gather', 'Unsqueeze', 'Squeeze',
            
            # Convolution operations
            'Conv', 'ConvTranspose', 'MaxPool', 'AveragePool', 'GlobalAveragePool',
            
            # Normalization
            'BatchNormalization', 'LayerNormalization', 'InstanceNormalization',
            
            # Reduction operations
            'ReduceSum', 'ReduceMean', 'ReduceMax', 'ReduceMin',
            
            # Comparison operations
            'Greater', 'Less', 'Equal', 'GreaterOrEqual', 'LessOrEqual',
            
            # Logical operations
            'And', 'Or', 'Not', 'Xor',
            
            # Shape operations
            'Shape', 'Size', 'Constant', 'Identity',
            
            # Padding and pooling
            'Pad', 'MaxPool', 'AveragePool',
            
            # Attention operations (basic)
            'Attention', 'MultiHeadAttention',
            
            # Other common operations
            'Dropout', 'Clip', 'Where', 'Select', 'Tile', 'Expand'
        }
        
        print(f"‚úÖ EZKL supports {len(supported_ops)} operation types:")
        for op in sorted(supported_ops):
            print(f"   - {op}")
        
        return supported_ops
    
    def identify_unsupported_operations(self, supported_ops: Set[str]) -> Set[str]:
        """Identify operations not supported by EZKL"""
        print("\n‚ö†Ô∏è  Identifying unsupported operations...")
        
        unsupported = self.operations - supported_ops
        supported = self.operations & supported_ops
        
        print(f"‚úÖ Supported operations ({len(supported)}):")
        for op in sorted(supported):
            print(f"   - {op}")
        
        if unsupported:
            print(f"\n‚ùå Unsupported operations ({len(unsupported)}):")
            for op in sorted(unsupported):
                print(f"   - {op}")
        else:
            print("\nüéâ All operations are supported by EZKL!")
        
        return unsupported
    
    def create_conversion_mapping(self) -> Dict[str, str]:
        """Create mapping for converting unsupported operations to supported ones"""
        print("\nüîÑ Creating operation conversion mapping...")
        
        conversion_map = {
            # Common conversions
            'Cast': 'Identity',  # Cast can often be ignored for inference
            'Resize': 'Reshape',  # Resize -> Reshape when possible
            'Upsample': 'Reshape',  # Upsample -> Reshape for simple cases
            'ReduceL2': 'Sqrt',  # ReduceL2 -> Sqrt when reducing to scalar
            'ReduceL1': 'ReduceSum',  # ReduceL1 -> ReduceSum approximation
            'HardSigmoid': 'Sigmoid',  # HardSigmoid -> Sigmoid approximation
            'HardSwish': 'Mul',  # HardSwish -> Mul approximation
            'Swish': 'Mul',  # Swish -> Mul approximation
            'Mish': 'Mul',  # Mish -> Mul approximation
            'LeakyRelu': 'Relu',  # LeakyRelu -> Relu approximation
            'Elu': 'Relu',  # Elu -> Relu approximation
            'Selu': 'Relu',  # Selu -> Relu approximation
            'Prelu': 'Relu',  # Prelu -> Relu approximation
            'ThresholdedRelu': 'Relu',  # ThresholdedRelu -> Relu approximation
            'Shrink': 'Relu',  # Shrink -> Relu approximation
            'Softplus': 'Relu',  # Softplus -> Relu approximation
            'Softsign': 'Tanh',  # Softsign -> Tanh approximation
            'LogSoftmax': 'Softmax',  # LogSoftmax -> Softmax approximation
            'Hardmax': 'Softmax',  # Hardmax -> Softmax approximation
            'MaxRoiPool': 'MaxPool',  # MaxRoiPool -> MaxPool approximation
            'RoiAlign': 'AveragePool',  # RoiAlign -> AveragePool approximation
            'GridSample': 'Reshape',  # GridSample -> Reshape approximation
            'NonMaxSuppression': 'Identity',  # NonMaxSuppression -> Identity (skip)
            'TopK': 'Identity',  # TopK -> Identity (skip)
            'ArgMax': 'Identity',  # ArgMax -> Identity (skip)
            'ArgMin': 'Identity',  # ArgMin -> Identity (skip)
            'Unique': 'Identity',  # Unique -> Identity (skip)
            'Compress': 'Identity',  # Compress -> Identity (skip)
            'Einsum': 'MatMul',  # Einsum -> MatMul for common cases
            'LpNormalization': 'Identity',  # LpNormalization -> Identity (skip)
            'LpPool': 'AveragePool',  # LpPool -> AveragePool approximation
            'GlobalLpPool': 'GlobalAveragePool',  # GlobalLpPool -> GlobalAveragePool
            'QLinearConv': 'Conv',  # QLinearConv -> Conv
            'QLinearMatMul': 'MatMul',  # QLinearMatMul -> MatMul
            'QLinearAdd': 'Add',  # QLinearAdd -> Add
            'QLinearMul': 'Mul',  # QLinearMul -> Mul
            'QLinearSigmoid': 'Sigmoid',  # QLinearSigmoid -> Sigmoid
            'QLinearSoftmax': 'Softmax',  # QLinearSoftmax -> Softmax
            'QLinearLeakyRelu': 'Relu',  # QLinearLeakyRelu -> Relu
            'QLinearConcat': 'Concat',  # QLinearConcat -> Concat
            'QLinearGlobalAveragePool': 'GlobalAveragePool',  # QLinearGlobalAveragePool -> GlobalAveragePool
            'QLinearAveragePool': 'AveragePool',  # QLinearAveragePool -> AveragePool
            'QLinearMaxPool': 'MaxPool',  # QLinearMaxPool -> MaxPool
            
            # Gemma-specific conversions
            'GroupQueryAttention': 'Identity',  # GroupQueryAttention -> Identity (skip for now)
            'RotaryEmbedding': 'Identity',  # RotaryEmbedding -> Identity (skip for now)
            'SimplifiedLayerNormalization': 'LayerNormalization',  # SimplifiedLayerNormalization -> LayerNormalization
        }
        
        print(f"‚úÖ Created conversion mapping for {len(conversion_map)} operations")
        return conversion_map
    
    def convert_unsupported_operations(self, unsupported_ops: Set[str], conversion_map: Dict[str, str]):
        """Convert unsupported operations to supported ones"""
        print("\nüîÑ Converting unsupported operations...")
        
        if not unsupported_ops:
            print("‚úÖ No operations to convert")
            return
        
        # Create a copy of the model for conversion
        converted_model = onnx.ModelProto()
        converted_model.CopyFrom(self.model)
        
        conversions_made = 0
        
        for node in converted_model.graph.node:
            if node.op_type in unsupported_ops:
                if node.op_type in conversion_map:
                    old_op = node.op_type
                    new_op = conversion_map[node.op_type]
                    node.op_type = new_op
                    
                    # Handle specific conversions
                    if new_op == 'Identity':
                        # Replace with identity operation - keep first input and output
                        node.input[:] = [node.input[0]]
                        node.output[:] = [node.output[0]]
                        node.attribute.clear()  # Remove attributes
                    elif new_op in ['Reshape', 'Sqrt', 'Mul']:
                        # Keep the operation but may need to adjust inputs/attributes
                        pass
                    
                    print(f"   üîÑ Converted {old_op} -> {new_op}")
                    conversions_made += 1
                else:
                    print(f"   ‚ö†Ô∏è  No conversion found for {node.op_type}")
        
        if conversions_made > 0:
            # Save converted model
            output_path = "model_converted.onnx"
            onnx.save(converted_model, output_path)
            print(f"‚úÖ Converted model saved as: {output_path}")
            print(f"   - {conversions_made} operations converted")
        else:
            print("‚ö†Ô∏è  No operations were converted")
    
    def create_simplified_model(self):
        """Create a simplified version of the model with only supported operations"""
        print("\nüîÑ Creating simplified model...")
        
        # Create a simple feedforward model that's EZKL compatible
        class SimplifiedGemmaModel(nn.Module):
            def __init__(self, vocab_size=1000, hidden_size=128):
                super().__init__()
                self.embedding = nn.Embedding(vocab_size, hidden_size)
                self.linear1 = nn.Linear(hidden_size, hidden_size * 2)
                self.linear2 = nn.Linear(hidden_size * 2, hidden_size)
                self.linear3 = nn.Linear(hidden_size, vocab_size)
                self.relu = nn.ReLU()
                self.layer_norm = nn.LayerNorm(hidden_size)
                
            def forward(self, x):
                x = self.embedding(x)
                x = self.layer_norm(x)
                x = self.relu(self.linear1(x))
                x = self.relu(self.linear2(x))
                x = self.linear3(x)
                return x
        
        # Create model with smaller dimensions for EZKL compatibility
        model = SimplifiedGemmaModel(
            vocab_size=1000,  # Reduced vocabulary
            hidden_size=128    # Reduced hidden size
        )
        model.eval()
        
        # Create sample input
        input_tensor = torch.randint(0, 1000, (1, 16))  # Batch size 1, sequence length 16
        
        # Export to ONNX
        os.makedirs("onnx_models", exist_ok=True)
        output_path = "onnx_models/simplified_gemma.onnx"
        
        torch.onnx.export(
            model,
            input_tensor,
            output_path,
            export_params=True,
            opset_version=11,
            do_constant_folding=True,
            input_names=['input_ids'],
            output_names=['logits'],
            dynamic_axes={
                'input_ids': {0: 'batch_size', 1: 'sequence_length'},
                'logits': {0: 'batch_size', 1: 'sequence_length'}
            }
        )
        
        print(f"‚úÖ Simplified model created: {output_path}")
        print("   - Compatible with EZKL")
        print("   - Reduced complexity for faster processing")
    
    def generate_ezkl_settings(self):
        """Generate EZKL settings for the converted model"""
        print("\nüîÑ Generating EZKL settings...")
        
        settings = {
            "run_args": {
                "input_scale": 7,
                "param_scale": 7,
                "scale_rebase_multiplier": 1,
                "lookup_range": [-32768, 32768],
                "logrows": 16,  # Increased for larger model
                "num_inner_cols": 4,
                "variables": [
                    ["batch_size", 1],
                    ["sequence_length", 16]
                ],
                "input_visibility": "Private",
                "output_visibility": "Public",
                "param_visibility": "Private",
                "rebase_frac_zero_constants": False,
                "check_mode": "UNSAFE",
                "commitment": "KZG"
            }
        }
        
        with open("ezkl_settings_converted.json", "w") as f:
            json.dump(settings, f, indent=2)
        
        print("‚úÖ EZKL settings generated: ezkl_settings_converted.json")
    
    def run_ezkl_verification(self):
        """Run EZKL to verify the converted model works"""
        print("\nüîÑ Running EZKL verification...")
        
        try:
            # Check if EZKL is available
            result = subprocess.run(["ezkl", "--version"], capture_output=True, text=True)
            print(f"‚úÖ EZKL version: {result.stdout.strip()}")
        except FileNotFoundError:
            print("‚ùå EZKL not found. Please install it first:")
            print("   pip install ezkl")
            return False
        
        # Generate sample input for the converted model
        sample_input = torch.randint(0, 1000, (1, 16)).numpy().tolist()
        with open("input_converted.json", "w") as f:
            json.dump(sample_input, f)
        
        print("‚úÖ Sample input generated: input_converted.json")
        
        # Try to generate circuit (this will test if the model is EZKL compatible)
        try:
            print("üîÑ Testing EZKL circuit generation...")
            subprocess.run([
                "ezkl", "gen-circuit",
                "-M", "onnx_models/simplified_gemma.onnx",
                "-S", "ezkl_settings_converted.json",
                "-O", "model_converted.compiled"
            ], check=True, capture_output=True)
            
            print("‚úÖ EZKL circuit generation successful!")
            print("   - Model is compatible with EZKL")
            print("   - Circuit saved as: model_converted.compiled")
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå EZKL circuit generation failed: {e}")
            print("   - Model may still have unsupported operations")
            return False
        
        return True

def main():
    """Main analysis and conversion function"""
    print("üöÄ Gemma ONNX Model Analysis and EZKL Conversion")
    print("=" * 60)
    
    analyzer = GemmaONNXAnalyzer()
    
    # Step 1: Load and analyze the model
    if not analyzer.load_model():
        print("‚ùå Failed to load model. Exiting.")
        return
    
    analyzer.analyze_operations()
    
    # Step 2: Check EZKL support
    supported_ops = analyzer.get_ezkl_supported_operations()
    
    # Step 3: Identify unsupported operations
    unsupported_ops = analyzer.identify_unsupported_operations(supported_ops)
    
    # Step 4: Create conversion mapping
    conversion_map = analyzer.create_conversion_mapping()
    
    # Step 5: Convert unsupported operations
    analyzer.convert_unsupported_operations(unsupported_ops, conversion_map)
    
    # Step 6: Create simplified model
    analyzer.create_simplified_model()
    
    # Step 7: Generate EZKL settings
    analyzer.generate_ezkl_settings()
    
    # Step 8: Test EZKL compatibility
    analyzer.run_ezkl_verification()
    
    print("\nüéâ Analysis and conversion completed!")
    print("\nüìÅ Generated files:")
    print("   - model_converted.onnx (converted original model)")
    print("   - onnx_models/simplified_gemma.onnx (EZKL-compatible model)")
    print("   - ezkl_settings_converted.json (EZKL settings)")
    print("   - input_converted.json (sample input)")
    print("   - model_converted.compiled (EZKL circuit)")
    
    print("\nüí° Summary:")
    print(f"   - Original operations: {len(analyzer.operations)}")
    print(f"   - EZKL supported: {len(analyzer.operations & supported_ops)}")
    print(f"   - EZKL unsupported: {len(unsupported_ops)}")
    print(f"   - Operations converted: {len(unsupported_ops & set(conversion_map.keys()))}")

if __name__ == "__main__":
    main()
